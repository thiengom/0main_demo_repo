const cds = require('../index'), { local, inspect } = cds.utils, { UPSERT } = cds.ql
const DEBUG = cds.debug('deploy')

const colors = !!process.stdout.isTTY && !!process.stderr.isTTY
const term = {
  x1b2: colors ? '\x1b[2m' : '',
  x1b0: colors ? '\x1b[0m' : '',
  info: colors ? (s => term.x1b2 + s + term.x1b0) : (s => s)
}

/**
 * Implementation of `cds.deploy` common to all databases.
 * It uses the database-specific `db.deploy` to prepare the database, e.g.
 * deploy create tables and views in case of a SQL database, then fills
 * in initial data, if present.
 */
exports = module.exports = function cds_deploy (model,options,csvs) { return {

  /** @param {cds.Service} db */
  async to (db, o = options || cds.options || {}) {
    if (!model)  throw new Error('Must provide a model or a path to model, received: ' + model)
    const LOG = o.silent || !cds.log('deploy')._info ? ()=>{} : console.log

    if (model && !model.definitions) {
      model = await cds.load (model) .then (cds.minify)
      if (DEBUG) try {
        DEBUG (`loaded model from ${model.$sources.length} file(s):\n${term.x1b2}`)
        for (let each of model.$sources)  console.log (' ', local(each))
      } finally {
        console.log (term.x1b0)
      }
    }

    if (o.mocked) exports.include_external_entities_in (model)
    else exports.exclude_external_entities_in (model)

    if (!db.run) db = await cds.connect.to(db)
    if (!cds.db) cds.db = cds.services.db = db
    if (!db.model) db.model = model

    // create tables & views...
    const any = await exports.create (db,model,o)
    if (!any && !csvs) return db

    // fill in initial data...
    await exports.init (db,model,o,csvs, file => LOG(
      term.info(` > init from ${local(file)}`)
    ))

    // done
    const file = db.getDbUrl(cds.context?.tenant)
    if (file !== ':memory:') LOG (`/> successfully deployed to ./${file}\n`)
    else LOG (`/> successfully deployed to sqlite in-memory db\n`)
    return db
  },

  // continue to support cds.deploy() as well...
  then(n,e) { return this.to (cds.db||'db') .then (n,e) },
  catch(e) { return this.to (cds.db||'db') .catch (e) },
}}



const { fs, path, read } = cds.utils
const { readdir } = fs.promises
const isdir = (..._) => fs.isdir(path.join(..._))
const isfile = (..._) => fs.isfile(path.join(..._))

exports.include_external_entities_in = function (model) {
  if (model._mocked) return model; else Object.defineProperty(model,'_mocked',{value:true})
  for (let each in model.definitions) {
    const def = model.definitions[each]
    if (def['@cds.persistence.mock'] === false) continue
    if (def['@cds.persistence.skip'] === true) {
      DEBUG && DEBUG ('including mocked', each)
      delete def['@cds.persistence.skip']
    }
  }
  exports.exclude_external_entities_in (model)
  return model
}

exports.exclude_external_entities_in = function (csn) { // NOSONAR
  // IMPORTANT to use cds.env.requires below, not cds.requires !!
  for (let [each,{service=each,model,credentials}] of Object.entries (cds.env.requires)) {
    if (!model) continue //> not for internal services like cds.requires.odata
    if (!credentials && csn._mocked) continue //> not for mocked unbound services
    DEBUG && DEBUG ('excluding external entities for', service, '...')
    const prefix = service+'.'
    for (let each in csn.definitions) if (each.startsWith(prefix)) _exclude (each)
  }
  return csn

  function _exclude (each) {
    const def = csn.definitions[each]; if (def.kind !== 'entity') return
    if (def['@cds.persistence.table'] === true) return // do not exclude replica table
    DEBUG && DEBUG ('excluding external entity', each)
    def['@cds.persistence.skip'] = true
    // propagate to all views on top...
    for (let other in csn.definitions) {
      const d = csn.definitions[other]
      const p = d.query && d.query.SELECT || d.projection
      if (p && p.from.ref && p.from.ref[0] === each) _exclude (other)
    }
  }
}

function getSqls(db, csn, o, beforeCsn) {
  const schemaEvo = (db.options?.schema_evolution === 'auto' || o.schema_evolution === 'auto')
  if (schemaEvo) {
    const { afterImage: afterCsn, drops, createsAndAlters: creas } = cds.compile.to.sql.delta (csn, o, beforeCsn);
    if(beforeCsn === undefined) {
      // If this is the first deployment done with automatic schema evolution, generate everything as if it was a drop create
      // but set the afterCsn in the db so we can calculate a delta going forward
      return { afterCsn, drops: creas.map (each => {
        let [, kind, entity] = each.match(/^CREATE (TABLE|VIEW) "?([^\s"(]+)/im) || []
        return `DROP ${kind} IF EXISTS ${entity};`
      }).reverse(), creas };
    }
    return { afterCsn, drops, creas };
  } else {
    const creas = cds.compile.to.sql(csn, o);
    const drops = creas.map (each => {
      let [, kind, entity] = each.match(/^CREATE (TABLE|VIEW) "?([^\s"(]+)/im) || []
      return `DROP ${kind} IF EXISTS ${entity};`
    }).reverse();
    return { afterCsn: {}, drops, creas };
  }
}

exports.create = async function (db, csn=db.model, o) {
  const schemaEvo = (db.options?.schema_evolution === 'auto' || o.schema_evolution === 'auto')
  if(db.deploy && !schemaEvo) {
    // reset CSN state saved in db - if there is any
    if(!o.dry) await db.run('DROP table if exists cds_Model;');
    return db.deploy(csn, o);
  }

  let beforeCsn
  if (schemaEvo) try {
    const [{ csn }] = await db.read('cds.Model')
    beforeCsn = JSON.parse(csn);
  } catch(e) {
    if (e.message.includes('no such table: cds_Model')) {
      await db.run('CREATE table cds_Model ( csn CLOB )')
      await db.insert({csn:''}).into('cds.Model')
    }
  }

  const { afterCsn, drops, creas } = getSqls(db, csn, o, beforeCsn);

  if (!creas || creas.length === 0) return
  if (o.dry) {
    console.log(); for (let each of drops) console.log(each,'\n')
    console.log(); for (let each of creas) console.log(each,'\n')
    return
  } else return db.run (async tx => {
    await tx.run(drops)
    await tx.run(creas)
    if (schemaEvo) {
      await tx.update('cds.Model').with({ csn: JSON.stringify(afterCsn) })
    }
    return true
  })
}


exports.init = (db, csn=db.model, o, csvs, log=()=>{}) => db.run (async tx => {

  const {tenant} = cds.context; if (tenant && tenant === cds.requires.multitenancy?.t0) return
  const schemaEvo = db.options?.schema_evolution === 'auto' || o?.schema_evolution === 'auto'
  const resources = await exports.resources(csn, {testdata: cds.env.features.test_data})
  const inits=[]

  if (csvs) {
    const ccsn = cds.compile.for['nodejs'](csn) // compile to calculate keys for newly added entities
    for(let [file,src] of Object.entries(csvs)) {
      const entity = _entity4(path.basename(file, '.csv'), csn)
      if (entity?.name) {
        const q = INSERT_from_csv (entity.name,src,schemaEvo); if (!q) continue
        if (db.kind === 'better-sqlite') _add_missing_pks2(q)
        q._target = ccsn.definitions[entity.name]
        inits.push (tx.run(q) .catch (e => {
          throw Object.assign (e, { message: 'in cds.deploy(): ' + e.message +'\n'+ inspect(q) })
        }))
      }
    }
  } else {
    for (let [file,e] of Object.entries(resources)) {
      if (e === '*') { // init.js/ts
        let x = await cds.utils._import(file);  if (!x) continue
        if (x.default)  x = x.default  // default ESM export
        inits.push (!x.then && typeof x === 'function' ? x(tx,csn) : x)
        log (file)
      } else { // from .csv or .json
        const INSERT_into = _from_csv_or_json [path.extname(file)]
        const src = await read(file,'utf8'); if (!src) continue
        const q = INSERT_into (e,src,schemaEvo); if (!q) continue
        if (db.kind === 'better-sqlite') _add_missing_pks2(q)
        if (cds.requires['cds.xt.ModelProviderService']?.kind === 'in-sidecar') q._target = csn.definitions[e]
        log (file,e)
        inits.push (tx.run(q) .catch (e => {
          throw Object.assign (e, { message: 'in cds.deploy(): ' + e.message +'\n'+ inspect(q) })
        }))
      }
    }
  }

  await Promise.all (inits)

  function _add_missing_pks2 (q) {
    const {columns,rows} =  q.UPSERT || q.INSERT // REVISIT: .entries are covered by current runtime. Should eventually also be handled here, as we likely don't do so in new db services
    if (columns) {
      const entity = csn.definitions[q._target.name], {uuid} = cds.utils
      for (let k in entity.keys) if (!columns.includes(k) && !entity.keys[k].isAssociation) {
        columns.push(k)
        const t = entity.keys[k]._type, pk = t === 'cds.UUID' ? uuid : index => index+1
        rows.forEach ((row,index) => row.push(pk(index)))
      }
    }
  }

})


exports.resources = async function (csn, opts) {
  if (!csn || !csn.definitions) csn = await cds.load (csn||'*') .then (cds.minify)
  const folders = await exports.resources.folders(csn, opts)
  const found={}, ts = process.env.CDS_TYPESCRIPT
  for (let folder of folders) {
    // fetching init.js files
    const init_js = ts && isfile(folder,'init.ts') || isfile(folder,'init.js')
    if (init_js) found[init_js] = '*'
    // fetching .csv and .json files
    for (let each of ['data','csv']) {
      const subdir = isdir(folder,each); if (!subdir) continue
      const files = await readdir (subdir)
      for (let fx of files) {
        if (fx[0] === '-') continue
        const ext = path.extname(fx); if (ext in _from_csv_or_json) {
          const f = fx.slice(0,-ext.length)
          if (/[._]texts$/.test(f) && files.some(g => g.startsWith(f+'_'))) {
            // ignores 'Books_texts.csv/json' if there is any 'Books_texts_LANG.csv/json'
            DEBUG && DEBUG (`ignoring '${fx}' in favor of translated ones`); continue
          }
          const e = _entity4(f,csn); if (_skip(e)) continue
          if (cds.env.features.deploy_data_onconflict === 'replace' && !/[._]texts_/.test(f)) {
            const seenBefore = Object.entries(found).find(([_, entity]) => entity === e.name )
            if (seenBefore) {
              DEBUG && DEBUG(`Conflict for '${e.name}': replacing '${local(seenBefore[0])}' with '${local(path.join(subdir,fx))}'`)
              continue
            }
          }
          found[path.join(subdir,fx)] = e.name
        }
      }
    }
  }
  return found
}


exports.resources.folders = async function (csn, o={}) {
  if (!csn || !csn.definitions) csn = await cds.load (csn||'*') .then (cds.minify)
  const folders = new Set (csn.$sources.map (path.dirname) .filter (f => f !== cds.home))
  if (cds.env.folders.db) folders.add (path.resolve(cds.root, cds.env.folders.db))
  if (o.testdata) folders.add (path.resolve(cds.root,'test/'))
  return folders
}


const _entity4 = (file,csn) => {
  const name = file.replace(/-/g,'.')
  const entity = csn.definitions [name]
  if (!entity) {
    if (/(.+)[._]texts_?/.test(name)) { // 'Books.texts', 'Books.texts_de'
      const base = csn.definitions [RegExp.$1]
      return base?.elements?.texts && _entity4 (base.elements.texts.target, csn)
    }
    else return DEBUG && DEBUG (`warning: ${name} not in model`)
  }
  // We also support insert into simple views if they have no projection
  const p = entity.query && entity.query.SELECT || entity.projection
  if (p && !p.columns && p.from.ref && p.from.ref.length === 1) {
    if (csn.definitions [p.from.ref[0]])  return entity
  }
  return entity.name ? entity : { name, __proto__:entity }
}

const INSERT_from_csv = (entity, csv, schemaEvo) => {
  let [ cols, ...rows ] = cds.parse.csv (csv)
  if (rows.length > 0) return (schemaEvo ? UPSERT : INSERT).into (entity) .columns (cols) .rows (rows)
}

const INSERT_from_json = (entity, json, schemaEvo) => {
  let records = JSON.parse (json)
  if (records.length > 0) return (schemaEvo ? UPSERT : INSERT).into (entity) .entries (records)
}

const _from_csv_or_json = { '.json': INSERT_from_json, '.csv': INSERT_from_csv, }
const _skip = e => !e || e['@cds.persistence.skip'] === true

/* eslint-disable no-console */
